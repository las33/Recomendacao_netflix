{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restam: 0\n"
     ]
    }
   ],
   "source": [
    "import itertools, json\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# dataset for test\n",
    "# dataset = [\n",
    "#     {\n",
    "#         'id': 0,\n",
    "#         'media': 4,\n",
    "#         'filmes':[\n",
    "#             {\n",
    "#                 'id': 0,\n",
    "#                 'avaliacao': 4,\n",
    "#                 'ano': 2010,\n",
    "#                 'mes': 5,\n",
    "#                 'dia': 9\n",
    "#             },\n",
    "#             {\n",
    "#                 'id': 2,\n",
    "#                 'avaliacao': 4,\n",
    "#                 'ano': 2010,\n",
    "#                 'mes': 5,\n",
    "#                 'dia': 9\n",
    "#             }\n",
    "#         ],\n",
    "#         'user_similarity':[\n",
    "#             [1, 5],\n",
    "#             [2, 4]\n",
    "#         ]\n",
    "#     },\n",
    "#     {\n",
    "#         'id': 1,\n",
    "#         'media': 3.5,\n",
    "#         'filmes':[\n",
    "#              {\n",
    "#                  'id': 1,\n",
    "#                  'avaliacao': 3,\n",
    "#                  'ano': 2012,\n",
    "#                  'mes': 6,\n",
    "#                  'dia': 12\n",
    "#              },\n",
    "#              {\n",
    "#                  'id': 3,\n",
    "#                  'avaliacao': 4,\n",
    "#                  'ano': 2012,\n",
    "#                  'mes': 6,\n",
    "#                  'dia': 12\n",
    "#              }\n",
    "#         ],\n",
    "#         'user_similarity':[\n",
    "#             [0, 4]\n",
    "#         ]\n",
    "#     },\n",
    "#     {\n",
    "#         'id': 2,\n",
    "#         'media': 3.7,\n",
    "#         'filmes':[\n",
    "#              {\n",
    "#                  'id': 2,\n",
    "#                  'avaliacao': 4,\n",
    "#                  'ano': 2012,\n",
    "#                  'mes': 6,\n",
    "#                  'dia': 12\n",
    "#              },\n",
    "#              {\n",
    "#                  'id': 3,\n",
    "#                  'avaliacao': 3,\n",
    "#                  'ano': 2012,\n",
    "#                  'mes': 6,\n",
    "#                  'dia': 12\n",
    "#              },\n",
    "#              {\n",
    "#                  'id': 4,\n",
    "#                  'avaliacao': 4,\n",
    "#                  'ano': 2012,\n",
    "#                  'mes': 6,\n",
    "#                  'dia': 12\n",
    "#              }\n",
    "#         ],\n",
    "#         'user_similarity':[\n",
    "#             [0, 4]\n",
    "#         ]\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "def find_item_by_id(item_id, data):\n",
    "    search = list(filter(lambda x: x['id'] == item_id, data))\n",
    "    if(len(search) == 1):\n",
    "        return search[0]\n",
    "    elif(len(search) > 1):\n",
    "        raise Exception(\"Not find.\")\n",
    "    \n",
    "def get_id_users(data):\n",
    "    return list(map(lambda x: x['id'], data))\n",
    "    \n",
    "def get_movies(user_id, data):\n",
    "    user = find_item_by_id(user_id, data)\n",
    "    return user['filmes']\n",
    "\n",
    "def non_watch_movies(user_movies, neighborhood, data):\n",
    "    all_nb_movies = list(map(lambda x: get_movies(x[0], data), neighborhood)) # all movies seen by the neighborhood\n",
    "    all_nb_movies = list(itertools.chain.from_iterable(all_nb_movies)) # [[]] -> []\n",
    "    all_nb_movies = list(set(map(lambda x: x['id'], all_nb_movies))) # IDs of all neighborhood movies\n",
    "    u_movies = list(map(lambda x: x['id'], user_movies)) # IDs of user movies\n",
    "    \n",
    "    return list(filter(lambda x: x not in u_movies, all_nb_movies)) # movies not seen by the user in his neighborhood\n",
    "\n",
    "def just_famous_movies(neighborhood, movies, n_movies, data): # (neighborhood) nearest neighborhood (e.g. 40 nearest users by similarity)\n",
    "    nb_ids = list(map(lambda x: x[0], neighborhood)) # id of (id, similarity)\n",
    "    nb = list(filter(lambda x: x['id'] in nb_ids, data)) # neighbors by id\n",
    "    filmes_nb = list(map(lambda x: x['filmes'], nb)) # rating of neighbors [[]]\n",
    "    filmes_nb = list(itertools.chain.from_iterable(filmes_nb)) # [[]] -> []\n",
    "    \n",
    "    if len(filmes_nb) == 0:\n",
    "        return {'famous_movies': []}\n",
    "    \n",
    "    filmes_nb = list(map(lambda x: x['id'], filmes_nb)) # IDs of filmes    \n",
    "    filmes_nb = list(map(lambda x: (x, filmes_nb.count(x)), movies)) # (movie, frequency)\n",
    "    filmes_nb.sort(key=lambda x: x[1], reverse=True) # sort by highest frequency\n",
    "    famous_movies = filmes_nb[:n_movies] # n popular movies\n",
    "    famous_movies = list(map(lambda x: x[0], famous_movies)) # only IDs, frequency is not necessary, just for ranking\n",
    "    \n",
    "#     if len(famous_movies) > 0: # hard to happen, but...\n",
    "        # search neighbors who watched at least one popular movie\n",
    "    nb_watched_famous_movies = list(filter(lambda x: any(movie in famous_movies for movie in list(map(lambda y: y['id'], x['filmes'])) ), nb))\n",
    "        \n",
    "        # return in 'nb' the users obj to ease later, but it can be just IDs\n",
    "    return {'famous_movies': famous_movies, 'nb': nb_watched_famous_movies}\n",
    "#     else:\n",
    "#         print(\"O valor de n = \", n, \" é muito grande. Não existe um filme que \", n, \" vizinhos assistiram.\")\n",
    "#         return {}\n",
    "    \n",
    "def find_similarity(neighborhood, user_id):\n",
    "    search = list(filter(lambda x: x[0] == user_id, neighborhood))\n",
    "    if(len(search) == 1):        \n",
    "        return search[0][1] # return only similarity value\n",
    "    else:\n",
    "        raise Exception('not find')\n",
    "\n",
    "all_predict = []\n",
    "unpredictable = []\n",
    "def predict_user_movie(user, n, min_movies, data):\n",
    "#     n = 2 # neighborhood\n",
    "#     min_movies = 1 # min value of filmes\n",
    "    \n",
    "    neighborhood = user['user_similarity']\n",
    "    neighborhood.sort(key=lambda x: x[1], reverse=True) # sort by similarity\n",
    "    neighborhood = neighborhood[:n] # the real neighborhood\n",
    "#     print(neighborhood)\n",
    "    \n",
    "    # movies watched by neighborhood but not by the user\n",
    "    non_watched_movies = non_watch_movies(user['filmes'], neighborhood, data)\n",
    "#     print(non_watched_movies)\n",
    "\n",
    "    # just the movies with high frequency within neighborhood\n",
    "    famous_movies = just_famous_movies(neighborhood, non_watched_movies, min_movies, data)\n",
    "#     print(famous_movies)\n",
    "    \n",
    "    if famous_movies['famous_movies'] == []:\n",
    "        unpredictable.append({'user_id': user['id']})\n",
    "    else:\n",
    "        nb = famous_movies['nb'] # users\n",
    "        famous_movies = famous_movies['famous_movies'] # movies IDs\n",
    "\n",
    "        nb_ids = list(map(lambda x: x['id'], nb)) # just IDs\n",
    "        neighborhood = list(filter(lambda x: x[0] in nb_ids, neighborhood)) # filter by IDs -> (user_id, similarity)\n",
    "    #     print(neighborhood)\n",
    "\n",
    "        pa_is = [] # final prediction (movie_id, prediction_value)\n",
    "\n",
    "        for movie_id in famous_movies:\n",
    "            sum_1 = 0\n",
    "            sum_2 = 0\n",
    "            for i in nb:\n",
    "                try:\n",
    "                    sim = find_similarity(neighborhood, i['id']) # search in list [(user_id, similarity)]\n",
    "                    mv = find_item_by_id(movie_id, i['filmes']) # retrieve movie in user movies list\n",
    "                    sum_1 = sum_1 + ((mv['avaliacao'] - i['media']) * sim)\n",
    "                    sum_2 = sum_2 + sim\n",
    "                except:\n",
    "                    pass # count zero\n",
    "            if sum_2 > 0:\n",
    "                pa_i = user['media'] + (sum_1/sum_2)\n",
    "            else:\n",
    "                pa_i = user['media']\n",
    "            pa_is.append({'filme':movie_id, 'predicao': pa_i})\n",
    "\n",
    "        all_predict.append({'id': user['id'], 'predicoes': pa_is})\n",
    "\n",
    "dataset = json.load(open('./usuarios.json'))\n",
    "\n",
    "users = get_id_users(dataset)\n",
    "# user = find_item_by_id(822109, dataset)\n",
    "# user\n",
    "# predict_user_movie(user, 20, 5, dataset)\n",
    "# print(all_predict)\n",
    "# print(unpredictable)\n",
    "tam = len(users)\n",
    "for id_user in users:\n",
    "    clear_output()\n",
    "    print(\"Restam:\", tam-1)\n",
    "    tam = tam-1\n",
    "    user = find_item_by_id(id_user, dataset)\n",
    "    predict_user_movie(user, 20, 5, dataset)\n",
    "\n",
    "with open('predictable.json', 'w') as outfile:\n",
    "    json.dump(all_predict, outfile)\n",
    "    \n",
    "with open('unpredictable.json', 'w') as outfile:\n",
    "    json.dump(unpredictable, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação dos dados disponíveis em treinamento e testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json, math\n",
    "from random import randrange\n",
    "\n",
    "dataset = json.load(open('./data.json'))\n",
    "\n",
    "def reservoir_sampling(items, k):\n",
    "    \"\"\" \n",
    "    Reservoir sampling algorithm for large sample space or unknow end list\n",
    "    See <http://en.wikipedia.org/wiki/Reservoir_sampling> for detail>\n",
    "    Type: ([a] * Int) -> [a]\n",
    "    Prev constrain: k is positive and items at least of k items\n",
    "    Post constrain: the length of return array is k\n",
    "    Credits: https://gist.github.com/m00nlight/bfe54d1b2db362755a3a\n",
    "    \"\"\"\n",
    "    sample = items[0:k]\n",
    "    \n",
    "    for i in range(k, len(items)):\n",
    "        j = randrange(1, i + 1)\n",
    "        if j < k:\n",
    "            sample[j] = items[i]\n",
    "\n",
    "    return sample\n",
    "\n",
    "filtered = list(filter(lambda x: len(x['filmes']) >= 3, dataset))\n",
    "# filtered = list(filter(lambda x: len(x['filmes']) >= 24, dataset)) # for tests\n",
    "\n",
    "trainset = []\n",
    "testset = []\n",
    "for item in filtered:\n",
    "    train = reservoir_sampling(item['filmes'], math.floor(len(item['filmes'])*.75))\n",
    "    test = list(filter(lambda x: x not in train, item['filmes']))\n",
    "    trainset.append({'id': item['id'], 'media': item['media'], 'filmes': train})\n",
    "    testset.append({'id': item['id'], 'media': item['media'], 'filmes': test})\n",
    "\n",
    "with open('train.json', 'w') as trainfile:\n",
    "    json.dump(trainset, trainfile)\n",
    "with open('test.json', 'w') as testfile:\n",
    "    json.dump(testset, testfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
